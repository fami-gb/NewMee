import { GoogleGenerativeAI } from "@google/generative-ai";

// .env.localã‹ã‚‰APIã‚­ãƒ¼ã‚’å–å¾—
const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);

export async function POST(request) {
  try {
    const { message } = await request.json();

    if (!message) {
      return new Response(JSON.stringify({ error: { message: 'Message is required.' } }), { status: 400 });
    }

    const model = genAI.getGenerativeModel({ model: "gemini-1.5-flash" });

    const chat = model.startChat({
      history: [
        {
          role: "user",
          parts: [{ text: `ã‚ãªãŸã¯ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ãªãƒ•ã‚¡ãƒƒã‚·ãƒ§ãƒ³ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼ã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ‚©ã¿ã«å¯¾ã—ã¦ã€ã‚®ãƒ£ãƒ«ã£ã½ãã€ãƒã‚¸ãƒ†ã‚£ãƒ–ã§ã€è¦ªã—ã¿ã‚„ã™ã„ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’ã—ã¦ãã ã•ã„ã€‚
MarkDownå½¢å¼ã¯ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„ã€‚æ”¹è¡Œã™ã‚‹éš›ã¯<br>ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚` }],
        },
        {
          role: "model",
          parts: [{ text: "OKï¼ä»»ã›ã¦ï¼ã©ã‚“ãªã“ã¨ã§ã‚‚èã„ã¦ã­ã€œğŸ’–" }],
        },
      ],
      generationConfig: {
        maxOutputTokens: 200,
      },
    });

    const result = await chat.sendMessage(message);
    const response = await result.response;
    const text = response.text();

    return new Response(JSON.stringify({ reply: text }), { status: 200 });

  } catch (error) {
    console.error("Error in Gemini API route:", error);
    return new Response(JSON.stringify({ error: { message: 'Internal Server Error' } }), { status: 500 });
  }
}
